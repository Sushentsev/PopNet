{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2g8GsawLEQ8"
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.4.0\n",
    "!pip3 install transformers==3.5.0\n",
    "!pip install lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92LqTByXLUpj",
    "outputId": "dc3d5f70-6996-4f47-8b6d-158eaf96c260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ru-gpts'...\n",
      "remote: Enumerating objects: 613, done.\u001b[K\n",
      "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
      "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
      "remote: Total 613 (delta 68), reused 46 (delta 24), pack-reused 505\u001b[K\n",
      "Receiving objects: 100% (613/613), 360.66 KiB | 504.00 KiB/s, done.\n",
      "Resolving deltas: 100% (368/368), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sberbank-ai/ru-gpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z_4fU-OYLcLi"
   },
   "outputs": [],
   "source": [
    "!mkdir models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ee0wFeNeL_s9",
    "outputId": "e7e6dd27-a064-4693-fb34-fe769f7fcf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PopNet'...\n",
      "remote: Enumerating objects: 159, done.\u001b[K\n",
      "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
      "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
      "remote: Total 159 (delta 25), reused 145 (delta 15), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (159/159), 8.01 MiB | 12.36 MiB/s, done.\n",
      "Resolving deltas: 100% (25/25), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Sushentsev/PopNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee8Z7FQ9P-7i",
    "outputId": "4fcad4b5-9692-4f6a-d495-13fc6d72f7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/PopNet/data\n"
     ]
    }
   ],
   "source": [
    "%cd PopNet/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN34UVeXQrSj",
    "outputId": "13036158-180e-4eaf-edb9-ac8534dfea70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples\t      genius_examples  lyrics_collection.py\n",
      "genius_collection.py  gensongs.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CZ_Fo0Kw_md"
   },
   "outputs": [],
   "source": [
    "!unzip gensongs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFBv1RJcdA1B"
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCM8n2ZG1kFo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('artists.txt', 'r')\n",
    "artists = []\n",
    "\n",
    "for line in f:\n",
    "    if re.match('— (.*)', line) and not re.match('— (.*)( \\(Верифицирован.*\\))', line):\n",
    "        artists.append(line.strip()[2:])\n",
    "\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYHc4KBXWWlR"
   },
   "outputs": [],
   "source": [
    "!python genius_collection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wfxl3wFnwCA3",
    "outputId": "e0a9599d-1ad7-4013-90b4-d1c3c9d7dfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9191"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "len(os.listdir('genius_examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZb0TjRY9BZf"
   },
   "outputs": [],
   "source": [
    "!zip -r gensongs.zip genius_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9A6-6MZ9rXq",
    "outputId": "d327beb8-31f3-4648-d57a-00aa346342f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main a4c2deb] songs\n",
      " 2 files changed, 22 insertions(+), 19 deletions(-)\n",
      "Counting objects: 5, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 7.94 MiB | 8.97 MiB/s, done.\n",
      "Total 5 (delta 3), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
      "To https://github.com/Sushentsev/PopNet.git\n",
      "   8e28dc4..a4c2deb  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add /content/PopNet/data/genius_collection.py\n",
    "!git add /content/PopNet/data/gensongs.zip\n",
    "\n",
    "!git config --global user.email \"grazder@yandex.ru\"\n",
    "!git config --global user.name \"grazder\"\n",
    "\n",
    "!git commit -m 'songs'\n",
    "\n",
    "!git push "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D10JgNEiP9HF"
   },
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c2IG3GZhM1Z4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = '/content/PopNet/data/genius_examples/'\n",
    "\n",
    "files = os.listdir(path)\n",
    "train_files, valid_files = files[:int(len(files) * 0.8)], files[int(len(files) * 0.8):]\n",
    "\n",
    "names = [x.split('-')[1][:-4] for x in train_files]\n",
    "files = [os.path.join(path, x) for x in train_files]\n",
    "\n",
    "train_file = open('train.txt', 'w')\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    f = open(file, \"r\")\n",
    "    train_file.write('<startsong>\\n')\n",
    "    train_file.write('<songname>' + name + '\\n')\n",
    "    train_file.write('<songlyrics>\\n')\n",
    "\n",
    "    for line in f:\n",
    "        train_file.write(line)\n",
    "\n",
    "    train_file.write('<endsong>\\n')\n",
    "    f.close()\n",
    "\n",
    "train_file.close()\n",
    "\n",
    "names = [x.split('-')[1][:-4] for x in valid_files]\n",
    "files = [os.path.join(path, x) for x in valid_files]\n",
    "valid_file = open('valid.txt', 'w')\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    f = open(file, \"r\")\n",
    "    valid_file.write('<startsong>\\n')\n",
    "    valid_file.write('<songname>' + name + '\\n')\n",
    "    valid_file.write('<songlyrics>\\n')\n",
    "\n",
    "    for line in f:\n",
    "        valid_file.write(line + '<newline>')\n",
    "\n",
    "    valid_file.write('<endsong>\\n')\n",
    "    f.close()\n",
    "\n",
    "valid_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8UHXaxVf25w",
    "outputId": "ccee6cd9-00e3-4bde-bd45-74e0b918304b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5k5h1beJN2fg",
    "outputId": "41498c55-186d-4807-cb25-578b7067c37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-28 10:15:16.605148: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "05/28/2021 10:15:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/28/2021 10:15:20 - INFO - filelock -   Lock 139963881622992 acquired on /root/.cache/torch/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d.lock\n",
      "Downloading: 100% 608/608 [00:00<00:00, 482kB/s]\n",
      "05/28/2021 10:15:20 - INFO - filelock -   Lock 139963881622992 released on /root/.cache/torch/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d.lock\n",
      "05/28/2021 10:15:21 - INFO - filelock -   Lock 139963881208528 acquired on /root/.cache/torch/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef.lock\n",
      "Downloading: 100% 1.71M/1.71M [00:00<00:00, 4.96MB/s]\n",
      "05/28/2021 10:15:22 - INFO - filelock -   Lock 139963881208528 released on /root/.cache/torch/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef.lock\n",
      "05/28/2021 10:15:22 - INFO - filelock -   Lock 139963881647760 acquired on /root/.cache/torch/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f.lock\n",
      "Downloading: 100% 1.27M/1.27M [00:00<00:00, 3.75MB/s]\n",
      "05/28/2021 10:15:23 - INFO - filelock -   Lock 139963881647760 released on /root/.cache/torch/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f.lock\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/modeling_auto.py:837: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "05/28/2021 10:15:25 - INFO - filelock -   Lock 139963858231120 acquired on /root/.cache/torch/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693.lock\n",
      "Downloading:  14% 78.9M/551M [00:01<00:11, 40.8MB/s]05/28/2021 10:15:27 - INFO - filelock -   Lock 139963858231120 released on /root/.cache/torch/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693.lock\n",
      "Traceback (most recent call last):\n",
      "  File \"ru-gpts/pretrain_transformers.py\", line 782, in <module>\n",
      "    main()\n",
      "  File \"ru-gpts/pretrain_transformers.py\", line 705, in main\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_auto.py\", line 847, in from_pretrained\n",
      "    pretrained_model_name_or_path, *model_args, config=config, **kwargs\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\", line 926, in from_pretrained\n",
      "    local_files_only=local_files_only,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 955, in cached_path\n",
      "    local_files_only=local_files_only,\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1164, in get_from_cache\n",
      "    http_get(url_to_download, temp_file, proxies=proxies, resume_size=resume_size, user_agent=user_agent)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1036, in http_get\n",
      "    for chunk in r.iter_content(chunk_size=1024):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 751, in generate\n",
      "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 496, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 444, in read\n",
      "    data = self._fp.read(amt)\n",
      "  File \"/usr/lib/python3.7/http/client.py\", line 461, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/usr/lib/python3.7/http/client.py\", line 482, in readinto\n",
      "    def readinto(self, b):\n",
      "KeyboardInterrupt\n",
      "Downloading:  15% 82.0M/551M [00:02<00:12, 38.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=${PYTHONPATH}:/ru-gpts/\n",
    "!CUDA_VISIBLE_DEVICES=0 python ru-gpts/pretrain_transformers.py \\\n",
    "    --output_dir=models/popnet \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=train.txt \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=valid.txt \\\n",
    "    --per_gpu_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --block_size 2048 \\\n",
    "    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od7jPpsuQwVn"
   },
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "TsOU02vPQfow",
    "outputId": "988a91c4-487a-4f6c-9113-f371407be3f5"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f2fe6b2fa578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/popnet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/popnet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1642\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing relevant tokenizer files\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             )\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'models/popnet'. Make sure that:\n\n- 'models/popnet' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'models/popnet' is the correct path to a directory containing relevant tokenizer files\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "tok = GPT2Tokenizer.from_pretrained(\"models/popnet\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/popnet\").cuda()\n",
    "\n",
    "text = \"<startsong>\\n<songname> Дом\\n<songlyrics>\\n\"\n",
    "inpt = tok.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "out = model.generate(inpt.cuda(), max_length=500, repetition_penalty=5.0, do_sample=True, top_k=5, top_p=0.95, temperature=1)\n",
    "tok.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q6DuuLFRNnp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YFBv1RJcdA1B"
   ],
   "name": "popnet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
